{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb374863",
   "metadata": {},
   "source": [
    "# ##Wazzuf \n",
    "this project helps you to find jobs that required python, this program will take a tour in Wazzuf to collect some information about the job like ( Job Title, Company Name, Location, requirements, Post Date ).\n",
    "also, this code was set up to avoid the errors that happened because of changes in HTML code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03d36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "import pandas as pd\n",
    "job_title =[]\n",
    "company_name = []\n",
    "location_name = []\n",
    "links = []\n",
    "salary = []\n",
    "res =[]\n",
    "date = []\n",
    "page_num = 0\n",
    "round_n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bf8230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "page swiched\n",
      "1\n",
      "page swiched\n",
      "2\n",
      "page swiched\n",
      "3\n",
      "page swiched\n",
      "4\n",
      "page swiched\n",
      "5\n",
      "page swiched\n",
      "6\n",
      "page swiched\n",
      "7\n",
      "page swiched\n",
      "8\n",
      "page swiched\n",
      "9\n",
      "page swiched\n",
      "10\n",
      "page swiched\n",
      "11\n",
      "page swiched\n",
      "12\n",
      "page swiched\n",
      "13\n",
      "page swiched\n",
      "14\n",
      "page swiched\n",
      "15\n",
      "page swiched\n",
      "pages ended\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    result = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q=python&start={page_num}\")\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src , \"lxml\")\n",
    "    page_limit = int(soup.find(\"strong\").text)\n",
    "    if (page_num > page_limit // 15):\n",
    "        print(\"pages ended\")\n",
    "        break\n",
    "    print(page_num)\n",
    "    job_titles =  soup.find_all(\"h2\",{\"class\":\"css-m604qf\"})\n",
    "    company_names = soup.find_all(\"a\",{\"class\":\"css-17s97q8\"})\n",
    "    locations_names = soup.find_all(\"span\",{\"class\":\"css-5wys0k\"})\n",
    "    for i in range(len(job_titles)):\n",
    "        job_title.append(job_titles[i].text)\n",
    "        links.append(\"https://wuzzuf.net\"+job_titles[i].find(\"a\").attrs['href'])\n",
    "        company_name.append(company_names[i].text)\n",
    "        location_name.append(locations_names[i].text)\n",
    "    page_num +=1\n",
    "    print (\"page swiched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17fd02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info of job number:1\n",
      "info of job number:2\n",
      "info of job number:3\n",
      "info of job number:4\n",
      "info of job number:5\n",
      "info of job number:6\n",
      "info of job number:7\n",
      "info of job number:8\n",
      "info of job number:9\n",
      "info of job number:10\n",
      "info of job number:11\n",
      "info of job number:12\n",
      "info of job number:13\n",
      "info of job number:14\n",
      "info of job number:15\n",
      "info of job number:16\n",
      "info of job number:17\n",
      "info of job number:18\n",
      "info of job number:19\n",
      "info of job number:20\n",
      "info of job number:21\n",
      "info of job number:22\n",
      "info of job number:23\n",
      "info of job number:24\n",
      "info of job number:25\n",
      "info of job number:26\n",
      "info of job number:27\n",
      "info of job number:28\n",
      "info of job number:29\n",
      "info of job number:30\n",
      "info of job number:31\n",
      "info of job number:32\n",
      "info of job number:33\n",
      "info of job number:34\n",
      "info of job number:35\n",
      "error occurred during scraping\n",
      "info of job number:36\n",
      "info of job number:37\n",
      "info of job number:38\n",
      "info of job number:39\n",
      "info of job number:40\n",
      "info of job number:41\n",
      "info of job number:42\n",
      "info of job number:43\n",
      "info of job number:44\n",
      "info of job number:45\n",
      "info of job number:46\n",
      "error occurred during scraping\n",
      "info of job number:47\n",
      "info of job number:48\n",
      "info of job number:49\n",
      "info of job number:50\n",
      "info of job number:51\n",
      "info of job number:52\n",
      "info of job number:53\n",
      "info of job number:54\n",
      "info of job number:55\n",
      "info of job number:56\n",
      "info of job number:57\n",
      "info of job number:58\n",
      "info of job number:59\n",
      "info of job number:60\n",
      "info of job number:61\n",
      "info of job number:62\n",
      "info of job number:63\n",
      "info of job number:64\n",
      "info of job number:65\n",
      "info of job number:66\n",
      "info of job number:67\n",
      "info of job number:68\n",
      "info of job number:69\n",
      "info of job number:70\n",
      "info of job number:71\n",
      "info of job number:72\n",
      "info of job number:73\n",
      "info of job number:74\n",
      "info of job number:75\n",
      "info of job number:76\n",
      "info of job number:77\n",
      "info of job number:78\n",
      "info of job number:79\n",
      "info of job number:80\n",
      "info of job number:81\n",
      "info of job number:82\n",
      "info of job number:83\n",
      "info of job number:84\n",
      "info of job number:85\n",
      "info of job number:86\n",
      "info of job number:87\n",
      "info of job number:88\n",
      "info of job number:89\n",
      "info of job number:90\n",
      "info of job number:91\n",
      "info of job number:92\n",
      "info of job number:93\n",
      "info of job number:94\n",
      "info of job number:95\n",
      "info of job number:96\n",
      "info of job number:97\n",
      "info of job number:98\n",
      "info of job number:99\n",
      "info of job number:100\n",
      "info of job number:101\n",
      "info of job number:102\n",
      "info of job number:103\n",
      "info of job number:104\n",
      "info of job number:105\n",
      "info of job number:106\n",
      "info of job number:107\n",
      "info of job number:108\n",
      "info of job number:109\n",
      "info of job number:110\n",
      "info of job number:111\n",
      "info of job number:112\n",
      "info of job number:113\n",
      "info of job number:114\n",
      "info of job number:115\n",
      "info of job number:116\n",
      "info of job number:117\n",
      "info of job number:118\n",
      "info of job number:119\n",
      "info of job number:120\n",
      "info of job number:121\n",
      "info of job number:122\n",
      "info of job number:123\n",
      "info of job number:124\n",
      "info of job number:125\n",
      "info of job number:126\n",
      "info of job number:127\n",
      "info of job number:128\n",
      "info of job number:129\n",
      "info of job number:130\n",
      "info of job number:131\n",
      "info of job number:132\n",
      "info of job number:133\n",
      "info of job number:134\n",
      "info of job number:135\n",
      "info of job number:136\n",
      "info of job number:137\n",
      "info of job number:138\n",
      "info of job number:139\n",
      "info of job number:140\n",
      "info of job number:141\n",
      "info of job number:142\n",
      "error occurred during scraping\n",
      "info of job number:143\n",
      "info of job number:144\n",
      "info of job number:145\n",
      "info of job number:146\n",
      "info of job number:147\n",
      "info of job number:148\n",
      "info of job number:149\n",
      "error occurred during scraping\n",
      "info of job number:150\n",
      "info of job number:151\n",
      "info of job number:152\n",
      "info of job number:153\n",
      "info of job number:154\n",
      "info of job number:155\n",
      "info of job number:156\n",
      "info of job number:157\n",
      "info of job number:158\n",
      "info of job number:159\n",
      "info of job number:160\n",
      "info of job number:161\n",
      "info of job number:162\n",
      "info of job number:163\n",
      "info of job number:164\n",
      "info of job number:165\n",
      "info of job number:166\n",
      "info of job number:167\n",
      "info of job number:168\n",
      "info of job number:169\n",
      "info of job number:170\n",
      "info of job number:171\n",
      "info of job number:172\n",
      "error occurred during scraping\n",
      "info of job number:173\n",
      "info of job number:174\n",
      "info of job number:175\n",
      "info of job number:176\n",
      "info of job number:177\n",
      "info of job number:178\n",
      "info of job number:179\n",
      "info of job number:180\n",
      "info of job number:181\n",
      "info of job number:182\n",
      "info of job number:183\n",
      "info of job number:184\n",
      "info of job number:185\n",
      "info of job number:186\n",
      "info of job number:187\n",
      "info of job number:188\n",
      "info of job number:189\n",
      "info of job number:190\n",
      "info of job number:191\n",
      "info of job number:192\n",
      "info of job number:193\n",
      "info of job number:194\n",
      "info of job number:195\n",
      "info of job number:196\n",
      "info of job number:197\n",
      "info of job number:198\n",
      "info of job number:199\n",
      "info of job number:200\n",
      "info of job number:201\n",
      "info of job number:202\n",
      "info of job number:203\n",
      "info of job number:204\n",
      "info of job number:205\n",
      "info of job number:206\n",
      "info of job number:207\n",
      "info of job number:208\n",
      "info of job number:209\n",
      "info of job number:210\n",
      "info of job number:211\n",
      "info of job number:212\n",
      "info of job number:213\n",
      "info of job number:214\n",
      "info of job number:215\n",
      "info of job number:216\n",
      "info of job number:217\n",
      "info of job number:218\n",
      "info of job number:219\n",
      "info of job number:220\n",
      "info of job number:221\n",
      "info of job number:222\n",
      "info of job number:223\n",
      "info of job number:224\n",
      "info of job number:225\n",
      "info of job number:226\n",
      "info of job number:227\n",
      "info of job number:228\n",
      "info of job number:229\n",
      "info of job number:230\n",
      "info of job number:231\n",
      "info of job number:232\n",
      "info of job number:233\n",
      "info of job number:234\n",
      "info of job number:235\n",
      "info of job number:236\n",
      "info of job number:237\n",
      "info of job number:238\n"
     ]
    }
   ],
   "source": [
    "for link in links:\n",
    "    print (f\"info of job number:{round_n}\")\n",
    "    round_n += 1\n",
    "    result = requests.get(link)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "    requirments = soup.find(\"div\",{\"class\":\"css-1t5f0fr\"}).ul\n",
    "    respon_txt = \"\"\n",
    "    try:\n",
    "        for li in requirments.find_all(\"li\"):\n",
    "            respon_txt += li.text + \"|\"\n",
    "        respon_txt = respon_txt[:-2]\n",
    "        res.append(respon_txt)\n",
    "    except:\n",
    "        print(\"error occurred during scraping\")\n",
    "        continue\n",
    "    posted = soup.find(\"span\",{\"class\":\"css-182mrdn\"}).text\n",
    "    date.append(posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39bfb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = list(zip(job_title,company_name,location_name,links,date,res))\n",
    "with open(\"python_jobs.csv\", \"w\", newline=\"\") as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow([\"Job Title\",\"Company Name\", \"Loacation\", \"link\",\"post date\",\"requirments\"])\n",
    "    for i in range(len(z)):\n",
    "        try:\n",
    "            wr.writerow(list(z[i]))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca485c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
